
\newchap{Introduction}
\label{chap:1_intro}
\section{Motivation}
With the advent of technologies that can process huge amounts of data, many linguistic tasks that were originally very tiresome and expensive to do, can now be accomplished much faster. Well known examples for this branch called \ac{nlp} are machine translation or search engines. While much of this research is done with written language, technologies like \ac{asr} or \ac{tts} require the processing of large amounts of spoken language. In many such technologies it is necessary that phonetic transcriptions of written or spoken text are available. They are needed such that a \ac{tts} model can learn how to produce them as an intermediate step and eventually produce speech based on phonetic transcriptions. There are systems that can produce speech directly from orthography and question the necessity of phonetic transcriptions. When only little data is available, the training data might not be enough to train a orthography-to-phoneme system, making phonetic transcriptions necessary. Another reason for creating phonetic transcriptions is that it usage is not limited to speech applications \citep{mortensen-etal-2018-epitran}. They might also be used to compare languages on speech basis which is exactly the question asked in this thesis. In order to do that, there needs to be a lot of knowledge about how language works. Comparing languages and studying their similarities and differences is part of a well-established branch of traditional linguistics called comparative linguistics. The analysis of large amounts of text in any language is commonly referred to as corpus linguistics. Corpus linguistics allows for both qualitative and quantitative analysis of text. Although text can refer to written or spoken language, most corpora contain written text \citep{McEnery&Hardie.2011}. Multilingual corpora can be used to compare languages. If all of these different approaches are combined, we end up by what we could call comparative corpus phonetics. And this is essentially what is done in this master's thesis. 

The text group of the Language and Space lab at the University of Zurich maintains a project that provides such a multilingual corpus consisting of 100 language text samples \citep{UniversityofZurich.19.07.2021}. Those 100 languages are meant to be representative for all the world's languages which is explained in more detail in section \ref{corpus}. It is therefore meant to give insight on relations, similarities, differences or properties of individual languages or language families. Specifically, their goal is to use quantitative methods like statistical modelling, machine learning and information theory to study language variation and compare languages. While there are many different types of analyses that can be performed on those text samples, the question keeps coming up if analyses of speech versions of those languages might not be more accurate or give better insight. Although this is not sure and simply a suggestions, it needs to be proven that working on text versions only represents languages well enough to present generalizable results. This present thesis ties in with this open research question. The goal is to collect phonetic transcriptions of the corpus. The same analyses can be performed on the phonetic texts which can be compared to the text analysis. In order to add a phonetic corpus to the already existing one, various steps need to be performed which are outlined in section \ref{outline}.

\review{Add quick intro into corpus linguistics, quantitative analysis, this is essentially what is done with the corpus. \citep{McEnery&Hardie.2011}}

\review{Introduction to comparative linguistics at some place. \citep{Hock&Joseph.2019}}

\section{Goals \& methods}
The primary goal of this thesis is to create phonetic transcriptions of as many languages as possible which are in the already existing corpus. Given the explanations above, the steps I aim to conclude to reach this goal are the following:
\begin{enumerate}
 \item Data collection: The given dataset contains no phonetic transcriptions of those 100 languages. The first step is to find already existing data. 
 \item Phonetic transcriptions: As existing data will not be available in sufficient amounts to perform meaningful analysis, the next step is to actually create phonetic transcriptions of as many languages as possible of the corpus. 
 \item Calculations and Analysis: Once the transcriptions have been obtained, the newly created phonetic corpus can be analysed and calculations can be performed.
 \item Based on the steps before, I will answer the following final question: Is it essential for the study of multilingual corpora to perform analyses on phonetic text (i.e. speech representations) rather than only written text? \review{depends on what can be done before...}
\end{enumerate}

\section{Research questions}
\label{questions}
\begin{enumerate}
\item Is there any significant difference in comparing spoken or written languages?
\end{enumerate}

\section{Thesis structure}

The thesis is subdivided into \review{six} chapters including a final conclusion. Chapter \ref{chap:tech-background} sets the boundaries of the theoretical background. It presents the linguistic foundation of phonetics and phonology, an introduction to corpus linguistics or rather corpus phonetics and finally an overview of the possibilities for automated creation of phonetic transcriptions. Chapter \ref{chap:2_data} introduces to the struggle of data collection. It explains the various data types and how those can be used. Chapter \ref{chap:3_model} dives deeper into the possibilities for creating phonetic transcriptions and what models can be used to create those. Chapter \ref{chap:exp} presents my own experiments to create phonetic transcriptions of the corpus.


