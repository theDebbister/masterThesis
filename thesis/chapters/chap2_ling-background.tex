\newchap{Representations of written and spoken language}
\label{chap:ling-background}

From a linguistic point of view there are two high-level concepts that are important for this thesis. The first and most significant one is that of the \textbf{relation of written and spoken language}. Both spoken and written language are a way of representing a language in general. As I have already mentioned, computational linguistics deals mostly with written rather than spoken language, but what does traditional linguistics say about the relation of written and spoken language? Both written and spoken language are \textit{valid} representations of the same language. As we will see later in this chapter, mapping a spoken language to its written representation is far from easy and never perfect. Elaborated writing systems like we are used to today came only much later compared to language in general \citep{writing-systems, Hock&Joseph.2019}. The question that gave rise to this thesis is if writing systems can capture language as such well enough in order to analyze a language properly. Or if we need spoken representations as well. 

Whenever we study language we look at samples of that language. It is simply impossible to study an \textit{entire} language as we would need all texts that were ever produced in that language. Consequently, we need to ask ourselves how much and what material of a language is enough to study it properly. In order to do that we can make use of techniques and methods from corpus linguistics. In linguistics and also in computational linguistics we typically talk about a corpus when we talk about a huge dataset that is used to represent a language. It does not matter if the corpus contains written or spoken samples of a language although it is mostly written \citep{McEnery&Hardie.2011}. Corpus linguistics allows for both qualitative and quantitative analysis of text. Due to recent technological advancement it has become possible to store large digital collections of speech recordings and their aligned transcriptions. These possibilities gave rise to a wider acknowledgement of corpus phonetics. Corpus phonetics deals with an abundance of linguistic variation. In addition to language, style or vocabulary variation, there are differences in dialect and idiolect, physiological state of the speakers and their attitude \citep{Liberman.2019, Chodroff.19.07.2019}. In section \ref{nws} I will present an interesting study on corpus phonetics \citep{baird_evans_greenhill_2021}. The authors of the study aim to answer how much phonetic data is needed to cover all sounds of a language.

The second key concept is that of \textbf{multilingual analysis}. The corpus underlying this thesis is multilingual. I will introduce this corpus later in section \ref{sec:corpus}. While a multilingual corpus in itself is not uncommon, the specific goal of the team maintaining the corpus is to compare the languages and study their similarities. Comparing languages and studying their similarities and differences is part of a well-established branch of traditional linguistics called comparative linguistics. For example, \citet{gutierrez-vasques-etal-2021-characters} performed a study on a multilingual corpus comparing different subword tokenizations. They compared 47 languages to find out how languages can be tokenized such that it leads to similar distributions among that languages. This analysis was performed on written language and is an example for what could be done on a phonetic corpus as well.

While there is a lot that could be said about any of these topics, I am not going into more detail about these. The point I would like to make is that the task of creating phonetic transcriptions of a multilingual corpus with the long-term objective of comparing written and spoken language is deeply rooted in linguistics and not at all trivial. In the following sections I will mostly write about phonetics and phonology in general and writing systems.

\section{Phonetics and phonology}
\label{phonetics}
Given that phonetics and phonology is a sub-area of traditional linguistics and often only touched on superficially in computational linguistics, I will summarise the most important assumptions and terms that are necessary to understand what phonetic transcriptions are.
A very important terminological distinction is between phonetics and phonology. While phonetics refers to the study of actual sounds, phonology refers to the study of sound \textit{systems}. In phonetics, it is not so much important what the different sounds mean, but how they are produced and perceived and what different sounds a human being can produce and perceive at all. When it comes to human communication using spoken language, many of these sounds are not actually meaningful. A human being is perfectly capable of producing many different sounds but some of those just do not mean anything to other people. This becomes evident when looking at children that have to learn to produce sounds that have a meaning. The study of sound systems, phonology, is used to describe the set of sounds that make up a language. The sounds within a sound system of a language can be used to construct meaningful utterances. 

Example \ref{ex:phon} shows how the word `request' can be pronounced in English. The pronunciation is written in the \ac{ipalpha} which I will explain in more depth in section \ref{sec:ipa}. For now it is important to note that the same word can be pronounced differently.

\begin{covsubexamples}[preamble={Different pronunciations of the English word `request'. Note that example (d) is a incorrect pronunciation:}] \label{ex:phon}
\item \label{ex:phonetics} [\textipa{\:R I k w E s t}] %ɹ ɪ k w ɛ s t
\item \label{ex:phonetics2} [\textipa{\textsubring{\:R} I k w E s t}] %ɻ̥ ɪ k w ɛ s t 
\item \label{ex:phonetics3} [\textipa{r I k w E s t}] %r ɪ k w ɛ s t
\item \label{ex:phonetics4} [\textipa{b I k w E s t}] %b ɪ k w ɛ s t
\end{covsubexamples}

Example \ref{ex:phonetics} shows how the word `request' is pronounced in British English. Even someone that does not know the \ac{ipalpha} can see that the letter `r' can be mapped to the pronunciation symbol [\textipa{\:R}]. This pronunciation of the Latin letter `r' is a part of the British English phoneme inventory. Another English speaker might pronounce the /r/ a bit different as in example \ref{ex:phonetics2}. We can see that the pronunciation symbol, [\textipa{\textsubring{\:R}}], for the /r/ differs from the one in the first example. However, an English speaker would still understand the word `request' as the different pronunciation does not change the meaning of the word. In phonetic terms we would say that in the British English sound system there exists an abstract sound /r/ which is called the \textbf{phoneme} /r/. Note that we write a phoneme between slashes. Also, in our case there exist two \textbf{phones} [\textipa{\:R}] and [\textipa{\textsubring{\:R}}] which are specific sounds that can be used to pronounce the phoneme /r/. No matter which phone I use, it does not change the meaning of the word. Note that we write a phone between square brackets. In English, [\textipa{\textsubring{\:R}}] is an \textbf{allophone} of the phoneme /r/. Allophones are specific phones that are concrete realizations of the same phoneme. They can be used interchangably without changing the meaning. Very importantly, allophones are language specific. In other languages I cannot use the same phones to pronounce a phoneme. In example \ref{ex:phonetics3}, the `r' is mapped to the phone [\textipa{r}] which is part of the Spanish sound system. Although an English speaker would still understand the word, [\textipa{r}] is not an allophone of /r/ in English as typically English speakers do not say the `r' like in Spanish. The phone [\textipa{r}] does not exist in the typical English sound system. Each language therefore has a phoneme inventory of abstract sounds that exist in the language's sound system. Also, there is a set of phones which are concrete realizations of abstract phonemes. Further, for each phoneme in a language, there exist a few allophones which can be used to replace one another without changing the meaning of the utterance.    

When it comes to phonetic transcriptions, the difference between phoneme and phone is very important. When we speak about a phonemic transcription, also called \textbf{broad} transcription, we do not care about the exact sounds. If a person uses an allophone to pronounce the word, we still write down the respective phoneme. If we want a phonetic transcription, also called \textbf{narrow} transcription, we care about every detail of the pronunciation. If a person uses an allophone, we note down that allophone and not the respective phoneme. 

It is important to note at this point that the terms phonetic and phonemic, and phone and phoneme are sometimes used interchangeably. Their linguistic definition as given above is relatively clear while the definition on the computational side is often less strict. Strictly speaking, phonemic transcriptions are not allowed to contain allophones but should write the respective phoneme of that language. This will not always be the case when it comes to data used in language technology \citep{Lee&Ashby.2020}. Example \ref{ex:broad} shows a German broad transcription of the word `Anrede'. Example \ref{ex:broad2} shows a broad transcription of the German word `Anredefall' which should be pronounced the same except for the last additional part. However, as we can see in the example, the first part looks different. In the German sound system, the [\textipa{r}] is actually an allophone of [\textipa{\;R}]. Correctly speaking, the second example is wrong as in broad transcriptions, we are not allowed to use allophones. 

\begin{covexamples}
\item \label{ex:broad} Anrede: [\textipa{a n \;R e: d @}] %a n ʀ eː d ə
\item \label{ex:broad2} Anredefall: [\textipa{a n r e: d @ f a l}] %a n r eː d ə f a l
\end{covexamples}

The above example is from the actual datasets I will be using later (see section \ref{sec:dataset}). 

In the following, I will outline different terms and concepts that appear a lot in research and literature concerned with phonetics and phonetic transcriptions.

\subparagraph{Vowels and consonants} In order to categorize the sounds of different languages, sounds are typically split into vowels and consonants. The terms to describe both vowels and consonants are inspired by the physical position of the tongue and the mouth when the sound is produced. To describe vowels, we use the position of the tongue in the mouth and if the lips are rounded or not. Using those two categories enables us to distinguish every possible vowel. The position of the tongue in the mouth is described along two axes: The tongue can be moved from the back of the mouth cavity to the front. This is the back-front axis. The second axis is that the tongue can be moved up and down in the mouth. In phonetics, up and down is referred to as close and open. A vowel can then, for example, be described as close-back rounded. This means that in order to produce the sound, a person needs to move the tongue up and back in the mouth and round the lips. Figure \ref{fig:ipa_chart} shows the vowel chart how it is usually represented in the \ac{ipalpha}. More on this special alphabet and writing systems in general follows in section \ref{sec:ipa}. 

Consonants are defined by the place and the manner of their physical production. The place, again, refers to the position of the tongue in the mouth and the overall form of the vocal tract. While for vowels we used the open-close and back-front schema to describe the position of the tongue, the consonant tongue positions are categorized differently. Table \ref{tab:consonants-place} shows all consonant place categories.
\tab{tab:consonants-place}{This table displays all tongue positions and shapes of the vocal tract that are used to produce consonants.}{
\begin{tabular}{llll}
bilabial           & labiodental         & dental              & alveolar     \\
postalveolar         & retroflex       & palatal                & velar          \\
uvular       & pharyngeal       & glottal                  & \\                      
\end{tabular}
}{Consonant place features}

\tab{tab:consonants-manner}{This table displays manner categories of consonants.}{
\begin{tabular}{llll}
plosive           & nasal         & trill              & tap or flap     \\
fricative         & lateral fricative       & approximant                & lateral approximant          \\     
\end{tabular}
}{Consonant manner features}

Unlike for vowels, for consonants the entire vocal tract, the lips and the tongue are used to block the air and make it flow in a specific way. For example, a dental consonant means that the tip of the tongue is pressed against the upper front teeth. For palatal consonants, the body of the tongue is pressed against the hard palate in the back of the mouth cavity.  
The manner of consonant production describes very precisely how the air is lead through the mouth to produce a sound \citep{phonetics-video}. Examples for the manner of a consonant are plosive or trill. For a trill the tongue needs to move in a vibrating way which consequently makes the air vibrate. Note that the place is not changed by this vibration. The tip of the tongue can still be pressed against the teeth or be in the back of the mouth while vibrating. A plosive first completely blocks the air such that no air can leave the mouth and then pushes the air out of the mouth in a fast manner, a bit like an explosion, therefore the name. The complete consonant chart is depicted in figure \ref{fig:ipa_chart} as well and table \ref{tab:consonants-manner} shows all consonant manner categories. In section \ref{sec:ipa} I will introduce the \ac{ipalpha} and give examples of how this alphabet helps us to write sounds with respect to the above introduced categories of vowels and consonants. 

\subparagraph{Syllables} Letters can be grouped into larger units called \textit{syllables}. Syllables can be an entire word or a part of a word. A syllable can be subdivided into different parts called \textit{onset}, \textit{nucleus} and \textit{coda}. For every syllable in every language it is true that the nucleus cannot be empty. The onset and the coda can be empty. Example \ref{ex:syllable} shows English words with syllable boundaries.
\begin{covsubexamples}[preamble={English syllables: the hyphen denotes a syllable boundary.}]
\label{ex:syllable}
\item \label{ex:syllable1} the-sis
\item \label{ex:syllable2} o-ver
\end{covsubexamples}
In English, the onset is typically a sequence of consonants. The nucleus is a sequence of vowels or just one vowel. The coda is another sequence of consonants. The second syllable in example \ref{ex:syllable1} follows this structure exactly: `s' is a consonant followed by a vowel `i' followed by another consonant `s'. The first syllable in example \ref{ex:syllable2} on the other hand, consists only of the nucleus, in this case the vowel `o'. Other than this three-part structure, syllables are organized very differently in different languages \citep{Intro.2007}. For computational analysis it is important that syllables are a way of segmenting written or spoken language. They are larger than individual letters or phonemes but often still smaller than individual morphemes or words. 

\subparagraph{Diphthongs}
A diphthong is a sequence of vowels that is considered as just one phoneme if is is within one syllable. If a syllable ends with a vowel and the next one starts with a vowel, this vowel sequence is not called a diphthong. An example is the German word `Chaos'. The two vowels in the middle are not a diphthong as there is a syllable boundary right in their middle: `Cha-os'. A word like `aus' contains a diphthong as it exists of only one syllable \citep{Intro.2007}. 

\subparagraph{Suprasegmentals} Apart from individual sounds, there are features of spoken language like stress or intonation. Those are referred to as suprasegmentals. They are often related to syllables. For example, we can put stress on a different syllable or raise the pitch. Semantically, some suprasegmentals in some languages distinguish meanings, some do not. A special case are tones. Tones are a special way of intonation. In some languages like Chinese or many African languages tones are used to distinguish meaning while in most European languages, the concept of tones does not exist \citep{Intro.2007}.

\section{Phonetic features}
As every language has a sound system and a set of phonemes that are part of that system, it is absolutely necessary that we can describe a phoneme very precisely. In computational analysis you would typically refer to a description of a phoneme as a set of features of that phoneme. For example, I could say that I use one feature to describe every phoneme. This one feature is if the phoneme is a consonant or not. If it is not a consonant, it is a vowel. With only one feature I cannot really distinguish different phonemes. In this case, I can in fact only distinguish vowels and consonants. Therefore we need to add more features to describe phonemes better. In linguistics it is very common to use the vowel and consonant schemes described above to describe each phoneme. But it is also possible to use a feature like `syllabic' that tells us whether a sound can be used as a syllable on its own or not. In section \ref{sec:phoible}  I will introduce a specific set of features that allows to describe many phonemes uniquely. 

\section{Mappings of written and spoken language}
\label{writing-sys}
Unlike spoken language that was a part of human interaction all the time, writing systems only developed over time. There are different writing systems that developed in different places at different times. The structure of the spoken language, the cultural context or the tools that were at hand to write are a few of many factors that influenced the emergence of a specific writing system. In general, we can think of writing systems as mappings from sounds to written symbols. The systems used to represent sounds in different languages do not uniquely map a letter to one specific phoneme. Most of the time, there is a standard pronunciation of each letter in every language. However, as we have seen above, there is the notion of allophones which means that every sound can be replaced by some other sounds which are also understood in this language. These explanations make clear that the mapping of written text to spoken text in various languages is complex. When taking a step back, we can see that a single letter can represent either a single phoneme, a syllable or a word or even something in between. The history and development of writing systems is an entire independent study area. Different writing systems developed in parallel which means that today, we have an abundance of different strategies to put sounds into writing. Not all writing systems, which are typically called scripts, can be treated the same and this most certainly has implications on models to create phonetic transcriptions. Each major script will be presented below \citep{writing-systems}. In the following I will use the terms letter or sign when referring to an individual building block of a writing system. In section \ref{sec:unicode_ipa}, I will introduce a more fine-grained terminology when referring to building blocks of writing systems and their computational representation. 

\begin{description}
\item[\textsc{Alphabet}] When a letter maps roughly to one phoneme, we call this an alphabet. In German, for example, the writing system consists of the Latin alphabet. The Latin alphabet is used for many different languages in western Europe and those languages that were influenced by colonisation. There are other alphabets like the Cyrillic or the Greek alphabet. If a language uses an alphabet this does not mean that each letter maps to exactly one phoneme. In fact, one letter can have many different realizations as example \ref{ex:latin-alpha} shows.
\begin{covsubexamples}[preamble={The examples show the different realizations of the English letter sequence `ough' \citep{phonetics-video}}. The first part is the letter sequence and the second part the phonetic transcription.]
\label{ex:latin-alpha}
\item t{\color{red}ough} \>\> [\textipa{t{\color{red}\textturnv f}}]
\item c{\color{red}ough} \>\> [\textipa{k{\color{red}\textturnscripta f}}]
\item th{\color{red}ough} \>\> [\textipa{\dh {\color{red}\textschwa \textupsilon}}]
\item thr{\color{red}ough} \>\> [\textipa{\texttheta r{\color{red}u:}}]
\item b{\color{red}ough} \>\>  [\textipa{b{\color{red}aU}}] %baʊ
\item br{\color{red}ough}t \>\> [\textipa{br{\color{red}O:t}}] %brɔːt
\end{covsubexamples}

The above examples show that it is not always clear how to pronounce a certain letter sequence. There is no simple one-to-one mapping from one letter or a sequence of letters to one phoneme or a sequence of phonemes within the English language. Let alone within all languages that use the Latin alphabet. In addition, alphabets typically have diacritic marks that can be used to extend the main letters. Just as with single letters, also diacritic marks cannot simply be mapped to a phoneme.

\item[\textsc{Abjad}] A special variant of an alphabet-language is abjad. Abjad represents only consonants and no vowels. This means that vowels need to be added while reading. Again, this means that there is a lot of ambiguity as it is not always clear which vowel should be added if there is no context. Semitic languages like Hebrew or Arabic make use of abjad.

\begin{covsubexamples}[preamble={Hebrew examples that are first mapped to Latin alphabet then to the Latin alphabet including vowels and in the end the English translation.}]
\label{ex:abjad}
\item \textcjheb{Ml.sb} \>\> bzlm \>\> bzelem \>\> name of an association
\item \textcjheb{Ml.sb} \>\> bzlm \>\> bzalam \>\> `their onion'
\end{covsubexamples}

Example \ref{ex:abjad} shows that in this case each letter maps to a consonant but it can be completed with different vowels. The words presented above do not have the same meaning depending on the vowels added although their letter sequence looks exactly the same. 

\item[\textsc{Syllabary}] In syllabaries, a letter, or rather a sign in this case, represents a syllable instead of a single sound. An example is the Korean script. Syllabaries typically do not have any internal ambiguities in their pronunciation as one sign maps to exactly one phoneme.   

\item[\textsc{Logographic systems}] Logographic systems represent entire words or morphemes as signs. Chinese is an example for a logographic system. We cannot break down Chinese signs into single morphemes or letters. One sign, which is called a logogram, is often pronounced in the same way regardless of the context of the sign. This means that the pronunciation of one sign is less ambiguous than, for example, the pronunciation of one letter in an alphabet. In contrast to alphabets, logographic systems have often thousands of signs while alphabets typically have less than one hundred letters. For each logogram, one must learn how to pronounce it as it cannot be derived form the sign itself.
\end{description}

As the examples above show, it is very difficult to have a clear mapping from sounds to written symbols. For most languages it is not possible to derive the exact pronunciation from the written symbols. Many of the pronunciation rules of a language are based on convention. Speakers of a language just \textit{know} how to pronounce a word. Still, there can arise heated debates about the correct pronunciation of certain words. An example are Swiss German dialects. In Switzerland, dialects are very important. Often, every town has their own dialect which people are proud of. This leads to an abundance of different pronunciations for one word. People are perfectly capable of understanding other dialects but just use their own pronunciation when it comes to speaking. As the personal way of speaking of often considered `normal' there are a lot of playful but also more serious discussions about correct pronunciations. Apart from these conventions, spoken and written languages change differently over time. Spoken languages are typically more flexible and ready to change while their written representation often stays the same \citep{unicode-lingu}. This can lead to official governmental interventions like the German orthography reform of 1996 that intended to adapt the German spelling to represent the German pronunciation more adequately. Also, major inventions like printing machines gave rise to standardization of writing systems as reading and writing became more common \citep{writing-systems}.

\section{The International Phonetic Alphabet (IPA)}
\label{sec:ipa}
The \ac{ipalpha} is a special alphabet where each letter is intended to represent exactly one phoneme  \citep{writing-systems, Intro.2007}. As usual, reality is more complex than what we wish it to be. Even with the \ac{ipalpha} there are inconsistencies. Figure \ref{fig:ipa_chart} shows the full \ac{ipalpha} chart including all characters that the \ac{ipa} decided to use. Although the \ac{ipalpha} seems very complete there are still sounds that cannot be represented using the \ac{ipalpha}. This becomes clear when, for example, looking at the vowel chart (see figure \ref{fig:ipa_chart}). The tongue does not `click into place' for the vowels on the chart. Vowel characterisation happens on a continuum. This means that it is always possible to characterize a vowel as in between two vowels on the chart.

When sounds are mapped to a written version we refer to this process as creating a transcription. When creating such transcriptions using the \ac{ipalpha} there are different levels of detail. Not all transcriptions represent the sounds in equal detail. Generally, there is the distinction of broad and narrow transcription. These two go back to the linguistic distinction of phone and phoneme as I have explained in section \ref{phonetics}. Broad transcriptions are less complex and usually easier to create and understand as they contain fewer details. Narrow transcriptions present every speaker individual or dialectal sounds as exactly as possible and are consequently more difficult to create. Narrow and broad transcriptions can diverge greatly. It is important to treat broad and narrow transcriptions as two different kinds of transcriptions. 

\begin{covexamples}
\item \label{exBro} \textipa{p\textsci\textprimstress kU k9\textprimstress\textrtailz 9f}
\item \label{exNar}\textipa{p\textsci\textprimstress k\super hU k\super h9\textprimstress\textrtailz 9f}
\end{covexamples}

Example \ref{exNar} is a narrow (phonetic) transcription of the beginning of the Mapudungun version of the short story \textit{The North Wind and the Sun}. The same text is transcribed broadly (phonemic) in example \ref{exBro}. As becomes clear in this example, the narrow transcriptions is longer as it contains more different characters. In this case it is only the superscript h that is different. The problem, with especially the narrow transcriptions, is that the transcriber still needs to define what narrow means in a specific case. One could argue that there are as many narrow transcriptions of a language as there are speakers of that language. This becomes tricky when given a task to automatically transcribe text. The training data might employ one definition of narrow, while there are texts in the test set that might follow another definition. This is mostly important when talking about data preprocessing and cleaning.
  



