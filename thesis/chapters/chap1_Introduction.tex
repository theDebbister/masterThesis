
\newchap{Introduction}
\label{chap:1_intro}

With the advent of technologies that can process huge amounts of data, many linguistic tasks that were originally very tiresome and expensive to do, can now be accomplished much faster. Well known examples for this branch called \ac{nlp} are machine translation or search engines. A lot of available tools and consequently research done in this area is concerned with written text. For many scenarios like machine translation, large corpora of written text in many languages are collected that are used to train computational models that solve those tasks. Following, there is an ever-growing set of models that are trained on written text. Often the goal is to reach or outperform human solutions to those various tasks. Those corpora serve as example for how the task in question can be accomplished. It is therefore necessary that this training data represents language well enough for a machine to reach that performance. From a linguistic point of view, the questions comes up if focusing on written language only can ever represent human language adequately. Most of communication and daily language use happens through speaking. This is a first potential limitation of many (written) language technologies. It is not easy to find out what characteristics of a language can be observed in written representations. There are technologies like \ac{asr} or \ac{tts} that require the mapping of written to spoken language. Spoken language in those cases is mostly represented as phonetic transcriptions as those are easier to process. Those research foci do contribute to the questions how spoken and written language relate. But still, this does not answer the question of how well written language represents language in general. The representative power of written text is much less studied. This is where this current thesis connects to cutting-edge research. I am going present my attempt of studying a multilingual phonetic corpus and comparing it to its written-text version. I will try to answer the following question: \textbf{Is it essential for the study of multilingual corpora to perform analyses on phonetic text (i.e. speech representations) rather than only written text?} It becomes clear, when looking at these considerations, that there are a few huge topics addressed. None of these is trivial and can be answered easily. While this thesis cannot possibly discuss everything from the use of phonetic transcriptions up to the nature of human language use, the aim is to make a step into the direction of quantifying the representative power of written text. 


\section{Research questions \& goals}
The text group of the Language and Space lab at the University of Zurich maintains a project that provides a multilingual corpus consisting of 100 language text samples \citep{UniversityofZurich.19.07.2021} which is referred to as 100LC (see section \ref{sec:corpus}). Those 100 languages are meant to be representative for all the world's languages which is explained in more detail in section \ref{corpus}. It is therefore meant to give insight on relations, similarities, differences or properties of individual languages or language families. Specifically, their goal is to use quantitative methods like statistical modelling, machine learning and information theory to study language variation and compare languages. The goal is now to collect phonetic transcriptions of the corpus. The same analyses that are performed on the original written corpus can be performed on the phonetic texts and both can be compared. In order to add a phonetic corpus to the already existing one, various steps need to be performed which are outlined below:
\begin{enumerate}
 \item \textbf{Data collection:} The given dataset contains no phonetic transcriptions of those 100 languages. The first step is to find already existing data. 
 \item \textbf{Phonetic transcriptions:} As existing data will not be available in sufficient amounts to perform meaningful analysis, the next step is to actually create phonetic transcriptions of as many languages as possible of the corpus. This will require to create and train a computational model.
 \item \textbf{Calculations and Analysis:} Once the transcriptions have been obtained, the newly created phonetic corpus can be analysed and calculations can be performed.
\end{enumerate}

The first two steps will already take up quite a lot of time which is hard to estimate in advance. It is not clear how much of the third step can be accomplished. I still think it is important to keep the bigger picture in mind and be aware of the overall importance of the topic. By performing these steps I am aiming at answering the following two questions:

\begin{enumerate}
\item What types of phonetic data is available and how can it be used?
\item Which computational models can be used to create phonetic transcriptions?
\item How can we use phonetic features to create phonetic transcriptions?
\item Is there any significant difference in comparing spoken or written languages?
\item Does written text represent language well enough to justify text-based research only?
\end{enumerate}

Again, the last two questions are related to the third step above. Those are important questions but it needs a lot of work to actually answer them. The third questions is of particular importance as it is a new approach to creating phonetic transcriptions. 

\section{Thesis structure}

The thesis is subdivided into six chapters of which the first chapter is this introduction. Chapter \ref{chap:ling-background} covers the linguistic basics that are necessary to understand the topic. It presents the linguistic foundation of phonetics and phonology and an introduction to corpus linguistics or rather corpus phonetics. Chapter \ref{chap:tech-background} sets the boundaries of the technical background. I will present an overview of the possibilities for automated creation of phonetic transcriptions. In chapter \ref{chap:data_collection}, I document my first practical experiments which are concerned with data collection. It contains a descriptions of the data I will later use to create models for phonetic transcriptions. Chapter \ref{chap:exp} presents my own experiments to create phonetic transcriptions of the corpus. I will present all models that I created and their results. Chapter \ref{chap:6_conclusion} summarizes my findings and presents ideas for future research.


