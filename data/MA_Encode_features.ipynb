{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MA_Encode_features.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q28bPFsyvjsN"
      },
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from segments import Tokenizer\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER = Tokenizer()"
      ],
      "metadata": {
        "id": "bO03XQ43UQXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf"
      ],
      "metadata": {
        "id": "uY3NFhZn1tah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phoible = pd.read_csv('phoible.csv', dtype=str)"
      ],
      "metadata": {
        "id": "8KUzxA2NeUXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_phonemes = pd.read_csv('phoible_features.csv', dtype=str)"
      ],
      "metadata": {
        "id": "9LP3j1SIc9Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langs = ['eng_latn_uk_broad_filtered', \n",
        "         'eng_latn_uk_narrow', \n",
        "         'eng_latn_us_broad_filtered', \n",
        "         'eng_latn_us_narrow', \n",
        "         'fra_latn_broad_filtered', \n",
        "         'ell_grek_broad_filtered', \n",
        "         'ell_grek_narrow', \n",
        "         'cmn_hani_broad', \n",
        "         'deu_latn_broad_filtered', \n",
        "         'deu_latn_narrow', \n",
        "         'eus_latn_broad', \n",
        "         'fin_latn_broad', \n",
        "         'fin_latn_narrow', \n",
        "         'ind_latn_broad', \n",
        "         'ind_latn_narrow', \n",
        "         'kat_geor_broad_filtered', \n",
        "         'mya_mymr_broad_filtered',\n",
        "         'spa_latn_ca_broad_filtered', \n",
        "         'spa_latn_ca_narrow', \n",
        "         'spa_latn_la_broad_filtered', \n",
        "         'kor_hang_narrow_filtered', \n",
        "         'jpn_hira_narrow_filtered', \n",
        "         'spa_latn_la_narrow', \n",
        "         'tgl_latn_broad', \n",
        "         'tgl_latn_narrow', \n",
        "         'tha_thai_broad', \n",
        "         'tur_latn_broad', \n",
        "         'tur_latn_narrow_filtered', \n",
        "         'hin_deva_broad_filtered', \n",
        "         'hin_deva_narrow', \n",
        "         'zul_latn_broad', \n",
        "         'vie_latn_hanoi_narrow_filtered', \n",
        "         'rus_cyrl_narrow', \n",
        "]"
      ],
      "metadata": {
        "id": "x_0ZvSnWcSBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in langs:\n",
        "\n",
        "    unique_phon = [unicodedata.normalize('NFC', char.strip()) for char in unique_phonemes['Phoneme'].to_list()]\n",
        "    unique_phonemes['Phoneme'] = unique_phon\n",
        "\n",
        "    print(f'CURRENT LANGUAGE: {lang}')\n",
        "\n",
        "    # reading the phoible subset for this language\n",
        "    lang_phoible = phoible[phoible['ISO6393'] == lang[:3]]\n",
        "\n",
        "    # get the cleaned wikipron data\n",
        "    current_lang = pd.read_csv('wikipron_clean/high/' + lang + '.tsv', dtype=str, sep='\\t', names=['grapheme', 'phoneme'], na_filter=False)\n",
        "    \n",
        "    # get the set of phonemes in the actual training data. All chars are normalized to match the other data\n",
        "    tokenized = ' '.join(current_lang['phoneme'].to_list())\n",
        "    current_phoneme_set = set([unicodedata.normalize('NFC', char.strip()) for char in tokenized.split()])\n",
        "    #current_phoneme_set_NFD = set([unicodedata.normalize('NFD', char.strip()) for char in tokenized.split()])\n",
        "\n",
        "    # get the phoible features for those phonemes in the language\n",
        "    phoible_subset = unique_phonemes[unique_phonemes.Phoneme.isin(current_phoneme_set)]\n",
        "    phoible_allophones = lang_phoible['Allophones'].dropna().to_list()\n",
        "    phoible_allophones = [char for all in phoible_allophones for char in all.split()]\n",
        "\n",
        "    diff = set(current_phoneme_set).difference(phoible_subset.Phoneme.to_list())\n",
        "    diff_allo = diff.difference(set(phoible_allophones))\n",
        "\n",
        "    for phon in diff_allo:\n",
        "        if phon.endswith('ː'):\n",
        "            new_phon = unique_phonemes[unique_phonemes['Phoneme'] == phon[:-1]]\n",
        "            new_phon['long'] = '+'\n",
        "            new_phon['Phoneme'] = phon\n",
        "            phoible_subset = phoible_subset.append(new_phon)\n",
        "            diff.remove(phon)\n",
        "    \n",
        "    phoible_subset = phoible_subset[phoible_subset['consonantal'] == '-']\n",
        "            \n",
        "    \n",
        "    # encode the dataset such that we can see what featuers correlate\n",
        "    encoded = phoible_subset.iloc[:,1:]\n",
        "    label_encoder = LabelEncoder()\n",
        "    for idx in range(encoded.shape[1]):\n",
        "        encoded.iloc[:,idx] = label_encoder.fit_transform(encoded.iloc[:,idx]).astype('float64')\n",
        "\n",
        "    # get the correlation matrix\n",
        "    current_corr = encoded.corr()\n",
        "    \n",
        "    # print heatmap for correlation if neccessary \n",
        "    # plt.subplots(figsize=(10, 7))\n",
        "    # sns.heatmap(current_corr)\n",
        "\n",
        "    # kick those features out whose correlation with another feature is above a certain threshold\n",
        "    columns = np.full((current_corr.shape[0],), True, dtype=bool)\n",
        "    for i in range(current_corr.shape[0]):\n",
        "        for j in range(i+1, current_corr.shape[0]):\n",
        "            if current_corr.iloc[i,j] >= 0.5:\n",
        "                if columns[j]:\n",
        "                    columns[j] = False\n",
        "    \n",
        "    # get those features, i.e. the colum names and retrieve it from the dataset\n",
        "    columns = np.insert(columns, 0, False)\n",
        "    selected_columns = phoible_subset.columns[columns]\n",
        "    # selected_columns = ['consonantal']\n",
        "    features = phoible_subset[selected_columns].drop_duplicates()\n",
        "    ratio = round(len(features) / len(phoible_subset), 3)\n",
        "\n",
        "    # create phonemes lists and their corresponsing features\n",
        "    all_phons_list = phoible_subset[['Phoneme']].values.flatten().tolist()\n",
        "    all_phones_features_list = phoible_subset[selected_columns].values.tolist()\n",
        "    \n",
        "    # ration of how many flags we have compared to the number of phonemes in the dataset, i.e. how many phonemes we can distinguish using the features\n",
        "    print(f'Ratio of number of phonemes and number of different flags: {ratio}')\n",
        "    print(f'Number of phonemes in this language: {len(current_phoneme_set)}')\n",
        "\n",
        "    chars = 'ABCDEFGHIJKLMN'\n",
        "    gen = itertools.product(chars, repeat=2)\n",
        "    \n",
        "    # create mapping from features to encoding\n",
        "    f1_dict = {}\n",
        "    for l in features.values:\n",
        "        f1_dict[''.join(l)] = ''.join(next(gen))\n",
        "\n",
        "    # create mapping from phoneme to encoded phoneme\n",
        "    phon_features = {}\n",
        "    c = Counter()\n",
        "    for p, f1 in zip(all_phons_list, all_phones_features_list):\n",
        "        c.update([f1_dict[''.join(f1)]])\n",
        "        phon_features[p] = p + ' ' + f1_dict[''.join(f1)]\n",
        "\n",
        "    # check what phonemes that are in the dataset are not in the phoible phonemes (without allophones)\n",
        "\n",
        "\n",
        "    i = 0\n",
        "    for ph in current_lang.phoneme.to_list():\n",
        "        if any([True for i in diff if i in ph]):\n",
        "            i += 1\n",
        "    \n",
        "    new_phones = []\n",
        "    for graph, phon in zip(current_lang[['grapheme']].values.tolist(), current_lang[['phoneme']].values.tolist()):\n",
        "        p = phon[0].split(' ')\n",
        "        new_p = ''\n",
        "        for char in p:\n",
        "            try:\n",
        "                char = phon_features[char]\n",
        "            except KeyError:\n",
        "                char = char\n",
        "            new_p += ' ' + char\n",
        "        new_phones.append([graph[0], new_p.strip()])\n",
        "\n",
        "    too_long = [p for p in new_phones if len(p[1].split()) > 30]\n",
        "    \n",
        "    new_df = pd.DataFrame(new_phones)\n",
        "    new_df.to_csv('wikipron_features/' + lang + '_FEATURES_v3.tsv', sep='\\t', header=False, index=False)\n",
        "    \n",
        "    print(f'Number of phonemes that are not expanded with a feature encoding: {i}')\n",
        "    print(f'Phonemes that are not found like that in phoible (without allophones): {diff}')\n",
        "    print(f'Number of pronunciations that are longer than 30 chars: {len(too_long)}\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ig82gyTwXP",
        "outputId": "b232203a-df8c-4fdf-dcb9-8de37f100881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CURRENT LANGUAGE: eng_latn_uk_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.306\n",
            "Number of phonemes in this language: 60\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 74\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: eng_latn_uk_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.236\n",
            "Number of phonemes in this language: 177\n",
            "Number of phonemes that are not expanded with a feature encoding: 101\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ʊʷ', 'aʰ', 'ŭ̥', 'ɹʲ', 'k̚', 't̚', 'ɹ̥ʷ', 'kˡ', 'ǀ', 'ʌˑ', 'ɹ̠̊ʷ', 'ʌˀ', 'ɒˀ', 'ɹ̠̊', 'ɹ̠ʷ', 'ɹ̠̝ʷ', 'ˀe', 'ɔ̹', 'ɹʷ', 'ɹ̝̊', 'bˡ', 'uːʷ', 'ĭ̥', 'ʉ̯', 'ɪˑ', 'æˀ', 'b̚', 'l̥ʰ', 'd̚', 'p̚', 'ɹ̠', 'iːʲ', 'æ̙', 'k̠ʰ', '˞', 'ɪʰ', 'ɫ̩'}\n",
            "Number of pronunciations that are longer than 30 chars: 1\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: eng_latn_us_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.314\n",
            "Number of phonemes in this language: 59\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 59\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: eng_latn_us_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.333\n",
            "Number of phonemes in this language: 206\n",
            "Number of phonemes that are not expanded with a feature encoding: 161\n",
            "Phonemes that are not found like that in phoible (without allophones): {'aʰ', 'ŭ̥', 'ɹʲ', 'ʊ̯̃', 'k̚', 'æ̝', 'ẽˑ', 'ʟ̩', 't̠̚', 't̚', 'ɹ̥ʷ', 'kˡ', 'ǀ', 'ʌˑ', 'ɹ̠̊ʷ', 'ʔ̚', 'ʌˀ', 'ə̯̃', 'd̥̚', 'ʊ̠', 'ɹ̠̊', 'ɹ̠ʷ', 'ɹ̠̝ʷ', 'ɚ̯', 'ˀe', 'ɑˀ', 'ɔ̹', 'ɹʷ', 'ɹ̝̊', 'ɹˠ', 'uːʷ', 'ĭ̥', 'ɪˑ', 'æˀ', 'ɛ̈', 'b̚', 'l̥ʰ', 'd̚', 'p̚', 'ɚ̹', 'ɹ̠', 'iːʲ', 'æ̙', 'ɚˑ', 't̬', 'k̠ʰ', '˞', 'ɫ̩'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: fra_latn_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.85\n",
            "Number of phonemes in this language: 39\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: ell_grek_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 1.0\n",
            "Number of phonemes in this language: 33\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: ell_grek_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.357\n",
            "Number of phonemes in this language: 50\n",
            "Number of phonemes that are not expanded with a feature encoding: 3\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ɐⁿ', 'ɐ̞', 'ɐᵐ'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: cmn_hani_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.926\n",
            "Number of phonemes in this language: 88\n",
            "Number of phonemes that are not expanded with a feature encoding: 13508\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ˀə', 'ˀɑ', 'ɛˀ', 'ʐ̩ˀ', 'ˀɛ', 'ˀa', 'z̩ˀ', 'ʑ̥', 'ˀʊ', 'ˀä', 'ˀɤˀ', 'ɻˀ', 'ɔˀ', 'ʐ̩', 'äˀ', 'ˀɔ', 'ʐ̥', 'ˀo', 'ˀɤ', 'ɪ̯ˀ', 'ʊ̯ˀ', 'ɤˀ', 'yˀ', 'ˀäˀ', 'ɤ̯̃'}\n",
            "Number of pronunciations that are longer than 30 chars: 282\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: deu_latn_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.556\n",
            "Number of phonemes in this language: 72\n",
            "Number of phonemes that are not expanded with a feature encoding: 3623\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ɐ̯̯', 'y̯', 'ɐ̯', 'ʏ̯', 'ɱ̩'}\n",
            "Number of pronunciations that are longer than 30 chars: 37\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: deu_latn_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.844\n",
            "Number of phonemes in this language: 132\n",
            "Number of phonemes that are not expanded with a feature encoding: 1638\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ʎ̞', 'ʁ̩', 'ʋ̥', 'ɐ̰', 'ʁ̥', 'ɛˤ', 'd̚', 'ʁ̞̊', 'ø̯', 'ɐ̯', 'ɱ̩', 'ɪ̯̯', 'ʁ̯', 'ʏ̯', 'a̯', 'p̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 18\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: eus_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.533\n",
            "Number of phonemes in this language: 41\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: fin_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.31\n",
            "Number of phonemes in this language: 63\n",
            "Number of phonemes that are not expanded with a feature encoding: 2401\n",
            "Phonemes that are not found like that in phoible (without allophones): {'y̯', 'ø̯'}\n",
            "Number of pronunciations that are longer than 30 chars: 465\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: fin_latn_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.357\n",
            "Number of phonemes in this language: 76\n",
            "Number of phonemes that are not expanded with a feature encoding: 8614\n",
            "Phonemes that are not found like that in phoible (without allophones): {'e̞̯', 'k̚', 'o̞̯', 'ɡ̚', 'ø̞̯', 'y̯', 'b̚', 'd̚', 'p̚', 't̪̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 442\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: ind_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.333\n",
            "Number of phonemes in this language: 58\n",
            "Number of phonemes that are not expanded with a feature encoding: 75\n",
            "Phonemes that are not found like that in phoible (without allophones): {'k̚', 'a̯', 't̚', 'p̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: ind_latn_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.792\n",
            "Number of phonemes in this language: 58\n",
            "Number of phonemes that are not expanded with a feature encoding: 229\n",
            "Phonemes that are not found like that in phoible (without allophones): {'k̚', 'u̪', 'a̯', 'a̝', 't̪̚', 't̚', 'p̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: kat_geor_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.5\n",
            "Number of phonemes in this language: 30\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 1\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: mya_mymr_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.375\n",
            "Number of phonemes in this language: 54\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 4\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: spa_latn_ca_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 1.0\n",
            "Number of phonemes in this language: 29\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 20\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: spa_latn_ca_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.412\n",
            "Number of phonemes in this language: 76\n",
            "Number of phonemes that are not expanded with a feature encoding: 1277\n",
            "Phonemes that are not found like that in phoible (without allophones): {'a̯', 'n̟', 'j̞', 'ɣ̞', 'θ̬'}\n",
            "Number of pronunciations that are longer than 30 chars: 11\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: spa_latn_la_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 1.0\n",
            "Number of phonemes in this language: 27\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 9\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: kor_hang_narrow_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.273\n",
            "Number of phonemes in this language: 58\n",
            "Number of phonemes that are not expanded with a feature encoding: 6459\n",
            "Phonemes that are not found like that in phoible (without allophones): {'k̚', 'ʌ̹', 't̚', 'p̚', 'ɕ͈'}\n",
            "Number of pronunciations that are longer than 30 chars: 4\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: jpn_hira_narrow_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.733\n",
            "Number of phonemes in this language: 60\n",
            "Number of phonemes that are not expanded with a feature encoding: 11128\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ɯ̟̊ᵝ', 'ã̠', 'ɨ̃ᵝ', 'ɯ̟ᵝ', 'p̚', 'k̚ʲ', 'ɨᵝ', 'k̚', 'ɨ̥ᵝ', 'ɰᵝ', 'p̚ʲ', 't̚', 'ɯ̟̃ᵝ'}\n",
            "Number of pronunciations that are longer than 30 chars: 34\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: spa_latn_la_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.412\n",
            "Number of phonemes in this language: 73\n",
            "Number of phonemes that are not expanded with a feature encoding: 11\n",
            "Phonemes that are not found like that in phoible (without allophones): {'j̞', 'ɣ̞', 'a̯'}\n",
            "Number of pronunciations that are longer than 30 chars: 6\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: tgl_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.292\n",
            "Number of phonemes in this language: 57\n",
            "Number of phonemes that are not expanded with a feature encoding: 3\n",
            "Phonemes that are not found like that in phoible (without allophones): {'k̚', 'p̚', 't̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: tgl_latn_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.5\n",
            "Number of phonemes in this language: 37\n",
            "Number of phonemes that are not expanded with a feature encoding: 0\n",
            "Phonemes that are not found like that in phoible (without allophones): set()\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: tha_thai_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.304\n",
            "Number of phonemes in this language: 47\n",
            "Number of phonemes that are not expanded with a feature encoding: 6914\n",
            "Phonemes that are not found like that in phoible (without allophones): {'k̚', 'a̯', 't̚', 'p̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 52\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: tur_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.19\n",
            "Number of phonemes in this language: 81\n",
            "Number of phonemes that are not expanded with a feature encoding: 5\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ɑ̟', 'ɾ̝̊'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: tur_latn_narrow_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.4\n",
            "Number of phonemes in this language: 49\n",
            "Number of phonemes that are not expanded with a feature encoding: 3\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ɾ̝̊'}\n",
            "Number of pronunciations that are longer than 30 chars: 0\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: hin_deva_broad_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.478\n",
            "Number of phonemes in this language: 60\n",
            "Number of phonemes that are not expanded with a feature encoding: 97\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ʒʱ'}\n",
            "Number of pronunciations that are longer than 30 chars: 1\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: hin_deva_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.342\n",
            "Number of phonemes in this language: 91\n",
            "Number of phonemes that are not expanded with a feature encoding: 371\n",
            "Phonemes that are not found like that in phoible (without allophones): {'b̚', 'd̚', 'p̚', 'ʈ̚', 'ʒʱ', 'k̚', 't̪̚', 't̚', 'ɖ̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 1\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: zul_latn_broad\n",
            "Ratio of number of phonemes and number of different flags: 0.312\n",
            "Number of phonemes in this language: 55\n",
            "Number of phonemes that are not expanded with a feature encoding: 348\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ǃʰ', 'ǀʰ', 'ǁ', 'ǃ', 'ǀʱ', 'ǃʱ', 'ǁʰ', 'ǁʱ', 'ǀ'}\n",
            "Number of pronunciations that are longer than 30 chars: 1\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: vie_latn_hanoi_narrow_filtered\n",
            "Ratio of number of phonemes and number of different flags: 0.478\n",
            "Number of phonemes in this language: 57\n",
            "Number of phonemes that are not expanded with a feature encoding: 4707\n",
            "Phonemes that are not found like that in phoible (without allophones): {'əˀ', 'ɛˀ', 'ŋ̟ˀ', 'p̚', 'aːˀ', 'əːˀ', 'k̚', 'ɔˀ', 't̚', 'ɨˀ', 'k̟̚'}\n",
            "Number of pronunciations that are longer than 30 chars: 38\n",
            "\n",
            "\n",
            "CURRENT LANGUAGE: rus_cyrl_narrow\n",
            "Ratio of number of phonemes and number of different flags: 0.333\n",
            "Number of phonemes in this language: 91\n",
            "Number of phonemes that are not expanded with a feature encoding: 301733\n",
            "Phonemes that are not found like that in phoible (without allophones): {'ʲ'}\n",
            "Number of pronunciations that are longer than 30 chars: 233\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "for idx in range(df.shape[1]):\n",
        "    df.iloc[:,idx] = label_encoder.fit_transform(df.iloc[:,idx]).astype('float64')"
      ],
      "metadata": {
        "id": "EzfyqAX9w7Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(1, df.shape[1]):\n",
        "    print(np.unique(df.iloc[:,idx]))"
      ],
      "metadata": {
        "id": "_R8yzv5zxBru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df.corr()"
      ],
      "metadata": {
        "id": "6gdfSVpLz6DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(15, 12))\n",
        "sns.heatmap(corr)"
      ],
      "metadata": {
        "id": "YxpcAewI0kRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
        "for i in range(corr.shape[0]):\n",
        "    for j in range(i+1, corr.shape[0]):\n",
        "        if corr.iloc[i,j] >= 0.4:\n",
        "            if columns[j]:\n",
        "                columns[j] = False\n",
        "\n",
        "selected_columns = df.columns[columns]\n",
        "data = df[selected_columns]"
      ],
      "metadata": {
        "id": "2mNS9rj313YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otDppBqJILuJ",
        "outputId": "163e412b-f56a-415d-8132-5bb556603a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3164 entries, 0 to 3163\n",
            "Data columns (total 5 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   tone                3164 non-null   object\n",
            " 1   stress              3164 non-null   object\n",
            " 2   consonantal         3164 non-null   object\n",
            " 3   spreadGlottis       3164 non-null   object\n",
            " 4   constrictedGlottis  3164 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 123.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "BSFBuTQuwHDe",
        "outputId": "8751d8b7-40a4-40c8-9f29-58bafbb56c67"
      },
      "source": [
        "total_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Phoneme  tone stress syllabic short  long consonantal sonorant  \\\n",
              "count     3164  3164   3164     3164  3164  3164        3164     3164   \n",
              "unique    3164     3      3        9     5     7           7       11   \n",
              "top         χʷ     0      -        -     -     -           +        +   \n",
              "freq         1  3102   3102     1990  3019  2582        1876     1546   \n",
              "\n",
              "       continuant delayedRelease  ... retractedTongueRoot advancedTongueRoot  \\\n",
              "count        3164           3164  ...                3164               3164   \n",
              "unique         10             10  ...                   6                  4   \n",
              "top             +              0  ...                   0                  0   \n",
              "freq         1730           1596  ...                1978               1978   \n",
              "\n",
              "       periodicGlottalSource epilaryngealSource spreadGlottis  \\\n",
              "count                   3164               3164          3164   \n",
              "unique                    10                  4            11   \n",
              "top                        +                  -             -   \n",
              "freq                    1970               3092          2625   \n",
              "\n",
              "       constrictedGlottis fortis raisedLarynxEjective loweredLarynxImplosive  \\\n",
              "count                3164   3164                 3164                   3164   \n",
              "unique                  8      4                    8                      6   \n",
              "top                     -      -                    -                      -   \n",
              "freq                 2692   1964                 2915                   3070   \n",
              "\n",
              "       click  \n",
              "count   3164  \n",
              "unique     8  \n",
              "top        -  \n",
              "freq    1828  \n",
              "\n",
              "[4 rows x 38 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phoneme</th>\n",
              "      <th>tone</th>\n",
              "      <th>stress</th>\n",
              "      <th>syllabic</th>\n",
              "      <th>short</th>\n",
              "      <th>long</th>\n",
              "      <th>consonantal</th>\n",
              "      <th>sonorant</th>\n",
              "      <th>continuant</th>\n",
              "      <th>delayedRelease</th>\n",
              "      <th>...</th>\n",
              "      <th>retractedTongueRoot</th>\n",
              "      <th>advancedTongueRoot</th>\n",
              "      <th>periodicGlottalSource</th>\n",
              "      <th>epilaryngealSource</th>\n",
              "      <th>spreadGlottis</th>\n",
              "      <th>constrictedGlottis</th>\n",
              "      <th>fortis</th>\n",
              "      <th>raisedLarynxEjective</th>\n",
              "      <th>loweredLarynxImplosive</th>\n",
              "      <th>click</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>...</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "      <td>3164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3164</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>χʷ</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>+</td>\n",
              "      <td>+</td>\n",
              "      <td>+</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>3102</td>\n",
              "      <td>3102</td>\n",
              "      <td>1990</td>\n",
              "      <td>3019</td>\n",
              "      <td>2582</td>\n",
              "      <td>1876</td>\n",
              "      <td>1546</td>\n",
              "      <td>1730</td>\n",
              "      <td>1596</td>\n",
              "      <td>...</td>\n",
              "      <td>1978</td>\n",
              "      <td>1978</td>\n",
              "      <td>1970</td>\n",
              "      <td>3092</td>\n",
              "      <td>2625</td>\n",
              "      <td>2692</td>\n",
              "      <td>1964</td>\n",
              "      <td>2915</td>\n",
              "      <td>3070</td>\n",
              "      <td>1828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 38 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXWPAdzKzXP"
      },
      "source": [
        "chars1 = 'ABCDEFGH'\n",
        "chars2 = 'NOPQRST'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feMyI0wvNLAd"
      },
      "source": [
        "gen2 = itertools.product(chars1, repeat=3)\n",
        "gen1 = itertools.product(chars2, repeat=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'syllabic', 'nasal', 'labial', "
      ],
      "metadata": {
        "id": "m4sAfBcMMWC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m10aVS_GUmG"
      },
      "source": [
        "total_df[['Phoneme', 'tone', 'consonantal', 'stress', 'spreadGlottis', 'constrictedGlottis']].drop_duplicates(subset=['tone', 'consonantal', 'stress', 'spreadGlottis', 'constrictedGlottis'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "QtzkIabgDWCF",
        "outputId": "bd725a7b-f616-4e02-e5ca-584575b08d67"
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "df[df['consonantal'] == '+'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Phoneme</th>\n",
              "      <th>tone</th>\n",
              "      <th>stress</th>\n",
              "      <th>syllabic</th>\n",
              "      <th>short</th>\n",
              "      <th>long</th>\n",
              "      <th>consonantal</th>\n",
              "      <th>sonorant</th>\n",
              "      <th>continuant</th>\n",
              "      <th>delayedRelease</th>\n",
              "      <th>approximant</th>\n",
              "      <th>tap</th>\n",
              "      <th>trill</th>\n",
              "      <th>nasal</th>\n",
              "      <th>lateral</th>\n",
              "      <th>labial</th>\n",
              "      <th>round</th>\n",
              "      <th>labiodental</th>\n",
              "      <th>coronal</th>\n",
              "      <th>anterior</th>\n",
              "      <th>distributed</th>\n",
              "      <th>strident</th>\n",
              "      <th>dorsal</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>front</th>\n",
              "      <th>back</th>\n",
              "      <th>tense</th>\n",
              "      <th>retractedTongueRoot</th>\n",
              "      <th>advancedTongueRoot</th>\n",
              "      <th>periodicGlottalSource</th>\n",
              "      <th>epilaryngealSource</th>\n",
              "      <th>spreadGlottis</th>\n",
              "      <th>constrictedGlottis</th>\n",
              "      <th>fortis</th>\n",
              "      <th>raisedLarynxEjective</th>\n",
              "      <th>loweredLarynxImplosive</th>\n",
              "      <th>click</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1876</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>n̤s</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>+</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "      <td>+</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1876</td>\n",
              "      <td>1876</td>\n",
              "      <td>1851</td>\n",
              "      <td>1861</td>\n",
              "      <td>1617</td>\n",
              "      <td>1876</td>\n",
              "      <td>1237</td>\n",
              "      <td>1131</td>\n",
              "      <td>715</td>\n",
              "      <td>1611</td>\n",
              "      <td>1784</td>\n",
              "      <td>1804</td>\n",
              "      <td>1461</td>\n",
              "      <td>1663</td>\n",
              "      <td>1391</td>\n",
              "      <td>1392</td>\n",
              "      <td>1392</td>\n",
              "      <td>1158</td>\n",
              "      <td>945</td>\n",
              "      <td>638</td>\n",
              "      <td>926</td>\n",
              "      <td>1018</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1021</td>\n",
              "      <td>1876</td>\n",
              "      <td>1792</td>\n",
              "      <td>1792</td>\n",
              "      <td>876</td>\n",
              "      <td>1874</td>\n",
              "      <td>1517</td>\n",
              "      <td>1551</td>\n",
              "      <td>1832</td>\n",
              "      <td>1694</td>\n",
              "      <td>1844</td>\n",
              "      <td>1701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Phoneme  tone stress  ... raisedLarynxEjective loweredLarynxImplosive click\n",
              "count     1876  1876   1876  ...                 1876                   1876  1876\n",
              "unique    1876     1      1  ...                    6                      4     6\n",
              "top        n̤s     0      -  ...                    -                      -     -\n",
              "freq         1  1876   1876  ...                 1694                   1844  1701\n",
              "\n",
              "[4 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqJ-j2bZyAuB"
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "cons_f1 = df[df['consonantal'] == '+'][['continuant', 'sonorant', 'distributed', 'nasal', 'lateral', 'strident', 'delayedRelease']].drop_duplicates()\n",
        "\n",
        "cons_f2 = df[df['consonantal'] == '+'][['anterior', 'dorsal', 'coronal', 'labial', 'labiodental', 'retractedTongueRoot', 'advancedTongueRoot']].drop_duplicates()\n",
        "\n",
        "cons_f1.info()\n",
        "cons_f2.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqe7Hpm36SHd"
      },
      "source": [
        "cons_f1_dict = {}\n",
        "cons_f2_dict = {}\n",
        "for l in cons_f1.values:\n",
        "    cons_f1_dict['-' + ''.join(l)] = ''.join(next(gen2))\n",
        "\n",
        "for l2 in cons_f2.values:\n",
        "    cons_f2_dict['-' + ''.join(l2)] = ''.join(next(gen2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBbFqSMy6nIN",
        "outputId": "9f825c9c-22ef-4225-e9ad-2b3dbe8dc3ac"
      },
      "source": [
        "print(len(cons_f1_dict))\n",
        "print(len(cons_f2_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147\n",
            "91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhp6_1Fl6vaf"
      },
      "source": [
        "cons = df[df['consonantal'] == '+'][['Phoneme']].values.flatten().tolist()\n",
        "cons_f1_list = df[df['consonantal'] == '+'][['continuant', 'sonorant', 'distributed', 'nasal', 'lateral', 'strident', 'delayedRelease']].values.tolist()\n",
        "cons_f2_list = df[df['consonantal'] == '+'][['anterior', 'dorsal', 'coronal', 'labial', 'labiodental', 'retractedTongueRoot', 'advancedTongueRoot']].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4wgKaYA6vrA"
      },
      "source": [
        "phon_features_cons = {}\n",
        "num_cons = []\n",
        "\n",
        "for p, f1, f2 in zip(cons, cons_f1_list, cons_f2_list):\n",
        "    num_cons.append(cons_f1_dict['-' + ''.join(f1)] + cons_f2_dict['-' + ''.join(f2)])\n",
        "    phon_features_cons[p] = p + ' ' + cons_f1_dict['-' + ''.join(f1)] + ' ' + cons_f2_dict['-' + ''.join(f2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrkg7Lfe7J1W"
      },
      "source": [
        "phon_features_cons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ8x3YoSw_tX",
        "outputId": "ec5f6bab-26c8-4541-dff8-9f95b445970f"
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "non_cons_f1 = df[df['consonantal'] == '-'][['high', 'low', 'front', 'back', 'tense']].drop_duplicates()\n",
        "\n",
        "non_cons_f2 = df[df['consonantal'] == '-'][['nasal', 'labial', 'labiodental', 'syllabic', 'long', 'round']].drop_duplicates()\n",
        "\n",
        "non_cons_f2.info()\n",
        "non_cons_f1.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 101 entries, 0 to 3109\n",
            "Data columns (total 6 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   nasal        101 non-null    object\n",
            " 1   labial       101 non-null    object\n",
            " 2   labiodental  101 non-null    object\n",
            " 3   syllabic     101 non-null    object\n",
            " 4   long         101 non-null    object\n",
            " 5   round        101 non-null    object\n",
            "dtypes: object(6)\n",
            "memory usage: 5.5+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 209 entries, 0 to 3110\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   high    209 non-null    object\n",
            " 1   low     209 non-null    object\n",
            " 2   front   209 non-null    object\n",
            " 3   back    209 non-null    object\n",
            " 4   tense   209 non-null    object\n",
            "dtypes: object(5)\n",
            "memory usage: 9.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKRyjRvdNO-Z"
      },
      "source": [
        "non_cons_f1_dict = {}\n",
        "non_cons_f2_dict = {}\n",
        "for l in non_cons_f1.values:\n",
        "    non_cons_f1_dict['-' + ''.join(l)] = ''.join(next(gen1))\n",
        "\n",
        "for l2 in non_cons_f2.values:\n",
        "    non_cons_f2_dict['-' + ''.join(l2)] = ''.join(next(gen1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYcv9W8qxVbC",
        "outputId": "53345b80-fc3f-4307-be63-55d8f5beea73"
      },
      "source": [
        "print(len(non_cons_f1_dict))\n",
        "print(len(non_cons_f2_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QBdjXhYb3ZY"
      },
      "source": [
        "non_cons = df[df['consonantal'] == '-'][['Phoneme']].values.flatten().tolist()\n",
        "f1_list = df[df['consonantal'] == '-'][['high', 'low', 'front', 'back']].values.tolist()\n",
        "f2_list = df[df['consonantal'] == '-'][['tense', 'nasal', \n",
        "              'labial', 'labiodental', 'syllabic', 'long', 'round']].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT8XVayWqms6"
      },
      "source": [
        "phon_features_non_cons = {}\n",
        "num = []\n",
        "\n",
        "for p, f1, f2 in zip(non_cons, f1_list, f2_list):\n",
        "    num.append(non_cons_f1_dict['-' + ''.join(f1)]+non_cons_f2_dict['-' + ''.join(f2)])\n",
        "    phon_features_non_cons[p] = p + ' ' + non_cons_f1_dict['-' + ''.join(f1)] + ' ' + non_cons_f2_dict['-' + ''.join(f2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqp2IJ_HrinY"
      },
      "source": [
        " phon_features_non_cons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZL5aRaksS9B"
      },
      "source": [
        "all_features = {}\n",
        "all_features.update(phon_features_non_cons)\n",
        "all_features.update(phon_features_cons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXIjXaxh7oRb",
        "outputId": "8c337a1e-6331-4c77-8c1d-2472a4f88367"
      },
      "source": [
        "len(all_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3071"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm3m1JPk8Dyj"
      },
      "source": [
        "deu = pd.read_csv('/content/deu_latn_broad_filtered.tsv', sep='\\t', names=['g', 'p'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsos0vAk-73n"
      },
      "source": [
        "dp = deu[['p']].values.tolist()\n",
        "dg = deu[['g']].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P6ppt9k_nMU"
      },
      "source": [
        "import re\n",
        "PATTERN = r'[͡.̍͜]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3_NxME6-8j2"
      },
      "source": [
        "new_phones = []\n",
        "for graph, phon in zip(dg, dp):\n",
        "    p = phon[0].split(' ')\n",
        "    new_p = ''\n",
        "    for char in p:\n",
        "        char = re.sub(PATTERN, '', char)\n",
        "        try:\n",
        "            char = all_features[char]\n",
        "        except KeyError:\n",
        "            char = char\n",
        "        new_p += ' ' + char\n",
        "    new_phones.append([graph[0], new_p.strip()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHjLi-ab_hXI"
      },
      "source": [
        "new_phones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGrant8_BHFx"
      },
      "source": [
        "new_deu = pd.DataFrame(new_phones)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZYVfpF8D-44"
      },
      "source": [
        "new_deu.to_csv('deu_latn_broad_filtered_FEATURES.tsv', sep='\\t', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}